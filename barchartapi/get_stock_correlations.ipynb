{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_stock_correlations - \n",
    "1. Use the barchart api to retrieve stock historical data;\n",
    "2. Create a correlation matrix from the historical data; \n",
    "3. Get standard deviations from the historical data;\n",
    "4. Create long/short position information for each security retrieved\n",
    "5. Create a portolio VaR using all of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from os.path import expanduser\n",
    "from scipy.stats import norm\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to sys.path\n",
    "Within the barchart_api module, references like: ```from barchartapi import barchart_api``` will not work unless you append to sys.path the following folders:\n",
    "1. project working directory (which holds barchart_api.py),\n",
    "2. project directory,\n",
    "3. workspace directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_DIR = '../..' \n",
    "PROJECT_DIR = f'{WORKSPACE_DIR}/barchartapi' \n",
    "WORKING_DIR = f'{PROJECT_DIR}/barchartapi' \n",
    "if WORKING_DIR not in sys.path:\n",
    "    sys.path.append(WORKING_DIR)\n",
    "if PROJECT_DIR not in sys.path:\n",
    "    sys.path.append(PROJECT_DIR)\n",
    "if WORKSPACE_DIR not in sys.path:\n",
    "    sys.path.append(WORKSPACE_DIR)\n",
    "import barchart_api as bcapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Create paths to where you will store the history data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPBOX_MARKET_DATA_DIR = expanduser('~/Dropbox/market_data')\n",
    "# STOCKS_DIR = f'{DROPBOX_MARKET_DATA_DIR}/stocks'\n",
    "# !ls {STOCKS_DIR}\n",
    "STOCKS_DIR = f'./temp_folder/stocks'\n",
    "try:\n",
    "    os.makedirs(STOCKS_DIR)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Create an instance of BcHist\n",
    "1. must set bar_type to minutes, hour or daily\n",
    "2. must set interval\n",
    " * for minutes, set interval to 1, 5, 15, 30 or 60\n",
    " * for other types, see https://www.barchart.com/ondemand/api/getHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to 'free' or 'paid'\n",
    "endpoint = 'free' # free or paid\n",
    "\n",
    "# set the bar_type and the interval\n",
    "bar_type='minutes' # minutes, daily, monthly\n",
    "interval=30 # 1,5,15,30,60\n",
    "\n",
    "# create an instance \n",
    "api_key = open(f'./temp_folder/{endpoint}_api_key.txt','r').read()\n",
    "endpoint_type=f'{endpoint}_url'\n",
    "bch = bcapi.BcHist(api_key, bar_type=bar_type, interval=interval,endpoint_type = endpoint_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_portfolio(csv_path=None):\n",
    "    '''\n",
    "    fetch a portfolio to use below\n",
    "    '''\n",
    "    p = csv_path\n",
    "    if p is None:\n",
    "        p = './hi_volume_stocks.csv'\n",
    "    df_p = pd.read_csv(p)\n",
    "    df_p['under'] = df_p.symbol.apply(lambda s: s.split(\"_\")[0])    \n",
    "    pnames = list(df_p.under)\n",
    "    return (df_p,pnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get your portfolio\n",
    "(default is ./hi_volume_stocks.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tuple = get_portfolio()\n",
    "df_portfolio = p_tuple[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Main Loop to fetch history data from Barchart\n",
    "\n",
    "#### Inputs\n",
    "On each call to BcHist.get_history, provide:\n",
    " * a beginning yyyymmdd integer\n",
    " * an ending yyyymmdd integer\n",
    " * a short name like:\n",
    "  * a stock symbol like: SPY,USO,IBM, etc\n",
    "  * a futures symbol like: CLJ18, GCG19, ESH17, etc\n",
    "\n",
    "#### Outputs\n",
    "The get_history method will return a tuple, where:\n",
    " * tup[0] provides a status\n",
    "\n",
    "* tup[1] provides a pandas DataFrame of data, or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true will cause barchartapi to refetch csv data, \n",
    "#   false will cause it to bypass any short_name that already has a csv file in the path sn_path below\n",
    "delete_old_csv_file = False \n",
    "\n",
    "#  set a date range\n",
    "days_to_fetch = 120\n",
    "dt_end = datetime.datetime.now()\n",
    "dt_beg = dt_end - datetime.timedelta(days_to_fetch)\n",
    "beg_yyyymmdd = '%04d%02d%02d' %(dt_beg.year,dt_beg.month,dt_beg.day)#20181201\n",
    "end_yyyymmdd = '%04d%02d%02d' %(dt_end.year,dt_end.month,dt_end.day)#20190219\n",
    "\n",
    "\n",
    "# set up other ETF names that can be used as a hedge to the portfolio\n",
    "spydr_short_names = ['XLE','XLU','XLK','XLB','XLP','XLY','XLI','XLC','XLV','XLF']\n",
    "equity_etf_names = ['DIA','SPY','QQQ']\n",
    "commodity_etf_short_names = ['USO','UNG','DBC','DBA','GLD','USCI']\n",
    "currency_etf_short_names = ['FXY','FXE','FXB','FXF','FXC','FXA']\n",
    "# my_portfolio_short_names = ['XLE','SPY','USO','GLD','XLU','QQQ']\n",
    "\n",
    "# get the portfolio\n",
    "\n",
    "# set short_names to the desired list to get\n",
    "short_names = list(set(\n",
    "    p_tuple[1] + spydr_short_names + equity_etf_names + commodity_etf_short_names + currency_etf_short_names + commodity_etf_short_names))\n",
    "\n",
    "for short_name in short_names:\n",
    "    sn_path = f'{STOCKS_DIR}/{short_name}.csv'\n",
    "    if os.path.isfile(sn_path):\n",
    "        if delete_old_csv_file:\n",
    "            os.remove(sn_path)\n",
    "        else:\n",
    "            print(f'BYPASSING: {short_name}')\n",
    "            continue\n",
    "    print(f'get_history: {short_name} BEGIN {datetime.datetime.now()}')\n",
    "    tup = bch.get_history(short_name, beg_yyyymmdd, end_yyyymmdd)\n",
    "    print(f'get_history: {short_name} WRITING DATA {datetime.datetime.now()}')\n",
    "    tup[1].to_csv(sn_path,index=False)\n",
    "    print(f'get_history: {short_name} END {datetime.datetime.now()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Do something interesting with the returned data, like create a portfolio VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = None\n",
    "for short_name in short_names:\n",
    "    sn_path = f'{STOCKS_DIR}/{short_name}.csv'\n",
    "    df_temp = pd.read_csv(sn_path)\n",
    "    df_temp = df_temp[['timestamp','close']]\n",
    "    df_temp = df_temp.rename(columns={'close':f'{short_name}'})\n",
    "    if df_hist is None:\n",
    "        df_hist = df_temp.copy()\n",
    "    else:\n",
    "        df_hist = df_hist.merge(df_temp,how='inner',on='timestamp')\n",
    "df_corr = df_hist[df_portfolio.under].corr()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(set(list(df_hist.columns.values))-set(['timestamp']))\n",
    "bars_per_day = 8*2\n",
    "perc_of_day = 1/bars_per_day\n",
    "perc_of_year = perc_of_day/256\n",
    "std_series = df_hist[cols].pct_change().iloc[1:].std()/perc_of_year**.5\n",
    "df_std = pd.DataFrame({'stdev':list(std_series.values),'symbol':list(std_series.index.values)})\n",
    "df_std.sort_values('symbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positions = df_portfolio[['under','position']].rename(columns={'under':'symbol'})\n",
    "df_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get current prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(filter(lambda c:'time' not in c,df_hist.columns.values))\n",
    "vals = df_hist.iloc[-1:][cols].as_matrix().reshape(-1)\n",
    "df_prices = pd.DataFrame({'symbol':cols,'price':vals})[['symbol','price']]\n",
    "df_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge position, prices, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positions_2 = df_positions.merge(df_prices,how='inner',on='symbol')\n",
    "df_positions_3 = df_positions_2.merge(df_std,how='inner',on='symbol')\n",
    "df_positions_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create position VaR's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_CONFIDENCE = .99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positions_3['unit_var'] = df_positions_3.apply(lambda r: r.price * r.stdev * norm.ppf(VAR_CONFIDENCE) * (1/256)**.5 / r.price,axis=1 )\n",
    "df_positions_3['position_var'] = df_positions_3.apply(lambda r: r.unit_var * r.position * r.price ,axis=1 )\n",
    "df_positions_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create portfolio VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an spy standard deviation that is the historical average\n",
    "var_days = 1\n",
    "spy_usual_daily_std = .16 \n",
    "port_std = (df_positions_3.position_var.astype(float).as_matrix().T @ df_corr.astype(float).as_matrix() @ df_positions_3.position_var.astype(float).as_matrix())**.5\n",
    "port_var = port_variance**.5 * var_days**.5  * norm.ppf(VAR_CONFIDENCE) \n",
    "spy_curr_unit_var = float(df_std[df_std.symbol=='SPY'].stdev) * (var_days/256)**.5  * norm.ppf(VAR_CONFIDENCE) \n",
    "sp_dollar_equiv = port_var / spy_curr_unit_var \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'portolio VaR: {round(port_var,2)}')\n",
    "print(f\"sp {var_days} day{'s' if var_days>1 else ''} unit VaR: {round(spy_curr_unit_var,2)}\")\n",
    "print(f'Equivalent S&P position (in dollars): {round(sp_dollar_equiv,2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
